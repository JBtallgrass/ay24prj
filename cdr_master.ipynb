{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column_name(col):\n",
    "    # Convert to lowercase\n",
    "    col = col.lower()\n",
    "    \n",
    "    # Remove any content within square brackets\n",
    "    col = re.sub(r'\\[.*?\\]', '', col)\n",
    "    \n",
    "    # Replace spaces and hyphens with underscores\n",
    "    col = re.sub(r'[\\s-]', '_', col)\n",
    "    \n",
    "    # Remove any non-alphanumeric characters (except underscores)\n",
    "    col = re.sub(r'[^a-z0-9_]', '', col)\n",
    "    \n",
    "    # Remove duplicate underscores\n",
    "    col = re.sub(r'_+', '_', col)\n",
    "    \n",
    "    # Remove leading/trailing underscores\n",
    "    col = col.strip('_')\n",
    "    \n",
    "    # Correct common misspellings\n",
    "    col = col.replace('availibility', 'availability')\n",
    "    \n",
    "    return col\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    dataframes = []\n",
    "    initial_df = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "    correct_columns = normalize_column_names(initial_df.columns)\n",
    "    initial_df.columns = correct_columns\n",
    "\n",
    "    dataframes.append(initial_df)\n",
    "    print(f\"Read {csv_files[0]} successfully with {len(initial_df)} rows.\")\n",
    "\n",
    "    for file in csv_files[1:]:\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(folder_path, file))\n",
    "            df.columns = normalize_column_names(df.columns)\n",
    "            \n",
    "            if set(df.columns) != set(correct_columns):\n",
    "                print(f\"Warning: Columns in {file} do not match the initial file. Attempting to align columns.\")\n",
    "                for col in correct_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None\n",
    "                df = df[correct_columns]\n",
    "            \n",
    "            print(f\"Read {file} successfully with {len(df)} rows.\")\n",
    "            df.dropna(how='all', inplace=True)\n",
    "            dataframes.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file}: {e}\")\n",
    "\n",
    "    if dataframes:\n",
    "        folder_df = pd.concat(dataframes, ignore_index=True)\n",
    "        print(f\"Columns in the concatenated DataFrame: {folder_df.columns.tolist()}\")\n",
    "        \n",
    "        learner_id_column = next((col for col in folder_df.columns if 'learner_id' in col.lower()), None)\n",
    "        if learner_id_column:\n",
    "            folder_df['learner_id'] = folder_df[learner_id_column]\n",
    "        else:\n",
    "            print(\"Error: No 'learner_id' column found. Using index as learner_id.\")\n",
    "            folder_df['learner_id'] = folder_df.index.astype(str)\n",
    "\n",
    "        folder_df['team'] = pd.to_numeric(folder_df['learner_id'].str[:2], errors='coerce').astype('Int64')\n",
    "        folder_df['section'] = folder_df['learner_id'].str[-1]\n",
    "        \n",
    "        # Create base_id using first letter of last name, first letter of first name, and learner_id\n",
    "        folder_df['base_id'] = (folder_df['last_name'].str[0].fillna('') + \n",
    "                                folder_df['first_name'].str[0].fillna('') + \n",
    "                                folder_df['learner_id'])\n",
    "        \n",
    "        def create_unique_id(group):\n",
    "            if len(group) == 1:\n",
    "                return group['base_id']\n",
    "            else:\n",
    "                return group['base_id'] + '_' + (group.groupby('base_id').cumcount() + 1).astype(str)\n",
    "        \n",
    "        folder_df['unique_id'] = folder_df.groupby('base_id', group_keys=False).apply(create_unique_id)\n",
    "        \n",
    "        columns = folder_df.columns.tolist()\n",
    "        columns.remove('unique_id')\n",
    "        columns = ['unique_id'] + columns\n",
    "        folder_df = folder_df[columns]\n",
    "        \n",
    "        return folder_df\n",
    "    else:\n",
    "        print(f\"No dataframes to concatenate in {folder_path}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folders found: 17\n",
      "Folders to be processed:\n",
      "- data/data\\C100\n",
      "- data/data\\C200\n",
      "- data/data\\C300\n",
      "- data/data\\C400\n",
      "- data/data\\C500\n",
      "- data/data\\F100\n",
      "- data/data\\H100\n",
      "- data/data\\H400\n",
      "- data/data\\L100\n",
      "- data/data\\L400\n",
      "- data/data\\M000\n",
      "- data/data\\M100\n",
      "- data/data\\M200\n",
      "- data/data\\M300\n",
      "- data/data\\M400\n",
      "- data/data\\S100\n",
      "- data/data\\X100\n",
      "\n",
      "Processing folder: data/data\\C100\n",
      "Error processing folder data/data\\C100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\C200\n",
      "Error processing folder data/data\\C200:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\C300\n",
      "Error processing folder data/data\\C300:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\C400\n",
      "Error processing folder data/data\\C400:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\C500\n",
      "Error processing folder data/data\\C500:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\F100\n",
      "Error processing folder data/data\\F100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\H100\n",
      "Error processing folder data/data\\H100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\H400\n",
      "Error processing folder data/data\\H400:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\L100\n",
      "Error processing folder data/data\\L100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\L400\n",
      "Error processing folder data/data\\L400:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\M000\n",
      "Error processing folder data/data\\M000:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\M100\n",
      "Error processing folder data/data\\M100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\M200\n",
      "Error processing folder data/data\\M200:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\M300\n",
      "Error processing folder data/data\\M300:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\M400\n",
      "Error processing folder data/data\\M400:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Processing folder: data/data\\S100\n",
      "Error processing folder data/data\\S100:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\16842997.py\", line 29, in <module>\n",
      "    result_df = process_folder(folder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\balla\\AppData\\Local\\Temp\\ipykernel_7692\\4107296010.py\", line 34, in process_folder\n",
      "    correct_columns = normalize_column_names(initial_df.columns)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'normalize_column_names' is not defined. Did you mean: 'normalize_column_name'?\n",
      "\n",
      "\n",
      "Skipping unexpected folder: data/data\\X100\n",
      "\n",
      "Total folders processed: 0\n",
      "Expected folders: 16\n",
      "Missing folders: 16\n",
      "\n",
      "Processed folders:\n",
      "\n",
      "Missing folders:\n",
      "- C100\n",
      "- C200\n",
      "- C300\n",
      "- C400\n",
      "- C500\n",
      "- F100\n",
      "- S100\n",
      "- H100\n",
      "- H400\n",
      "- L100\n",
      "- L400\n",
      "- M000\n",
      "- M100\n",
      "- M200\n",
      "- M300\n",
      "- M400\n",
      "\n",
      "All available folders processed.\n",
      "\n",
      "Contents of the cleaned_data folder:\n",
      "- c100_compiled_dataframe.csv\n",
      "- c200_compiled_dataframe.csv\n",
      "- C300_compiled_dataframe.csv\n",
      "- C400_compiled_dataframe.csv\n",
      "- C500_compiled_dataframe.csv\n",
      "- F100_compiled_dataframe.csv\n",
      "- H100_compiled_dataframe.csv\n",
      "- H400_compiled_dataframe.csv\n",
      "- L100_compiled_dataframe.csv\n",
      "- L400_compiled_dataframe.csv\n",
      "- M000_compiled_dataframe.csv\n",
      "- M100_compiled_dataframe.csv\n",
      "- M200_compiled_dataframe.csv\n",
      "- M300_compiled_dataframe.csv\n",
      "- M400_compiled_dataframe.csv\n",
      "- S100_compiled_dataframe.csv\n",
      "- test_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "data_root = os.path.normpath(r'data/data')  # This should work for both Windows and Unix-like systems\n",
    "output_dir = 'cleaned_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "expected_folders = [\n",
    "    'C100', 'C200', 'C300', 'C400', 'C500', \n",
    "    'F100', 'S100', 'H100', 'H400', 'L100', 'L400', \n",
    "    'M000', 'M100', 'M200', 'M300', 'M400'\n",
    "]\n",
    "\n",
    "data_folders = [f.path for f in os.scandir(data_root) if f.is_dir()]\n",
    "print(f\"Total folders found: {len(data_folders)}\")\n",
    "print(\"Folders to be processed:\")\n",
    "for folder in data_folders:\n",
    "    print(f\"- {folder}\")\n",
    "\n",
    "processed_folders = 0\n",
    "processed_folder_names = []\n",
    "\n",
    "for folder in data_folders:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    if folder_name not in expected_folders:\n",
    "        print(f\"\\nSkipping unexpected folder: {folder}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nProcessing folder: {folder}\")\n",
    "    try:\n",
    "        result_df = process_folder(folder)\n",
    "        \n",
    "        if result_df is not None:\n",
    "            output_file = os.path.join(output_dir, f'{folder_name}_compiled_dataframe.csv')\n",
    "            result_df.to_csv(output_file, index=False)\n",
    "            print(f\"Data compiled and saved successfully to {output_file}\")\n",
    "            print(f\"Total rows in compiled dataframe: {len(result_df)}\")\n",
    "            \n",
    "            print(\"\\nSummary of rows per section:\")\n",
    "            print(result_df['section'].value_counts().sort_index())\n",
    "            \n",
    "            print(\"\\nSample data with reordered columns:\")\n",
    "            print(result_df.head(10))\n",
    "            \n",
    "            processed_folders += 1\n",
    "            processed_folder_names.append(folder_name)\n",
    "        else:\n",
    "            print(f\"No data processed for {folder}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder}:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(f\"\\nTotal folders processed: {processed_folders}\")\n",
    "print(f\"Expected folders: {len(expected_folders)}\")\n",
    "print(f\"Missing folders: {len(expected_folders) - processed_folders}\")\n",
    "\n",
    "print(\"\\nProcessed folders:\")\n",
    "for folder in processed_folder_names:\n",
    "    print(f\"- {folder}\")\n",
    "\n",
    "print(\"\\nMissing folders:\")\n",
    "for folder in expected_folders:\n",
    "    if folder not in processed_folder_names:\n",
    "        print(f\"- {folder}\")\n",
    "\n",
    "print(\"\\nAll available folders processed.\")\n",
    "\n",
    "# Check the contents of the cleaned_data folder\n",
    "print(\"\\nContents of the cleaned_data folder:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Report on files in the cleaned_data folder:\n",
      "==================================================\n",
      "\n",
      "File: c100_compiled_dataframe.csv\n",
      "Number of rows: 1061\n",
      "Number of columns: 19\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availibility\n",
      "  - total\n",
      "  - c100_final\n",
      "  - c100__idp\n",
      "  - c170_essay\n",
      "  - c172_brief\n",
      "  - c400_diag_exam\n",
      "  - f100_pretest_us\n",
      "  - f100_pretest_ims\n",
      "  - s100_pretest\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: c200_compiled_dataframe.csv\n",
      "Number of rows: 1061\n",
      "Number of columns: 17\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - c200_wt_ttl\n",
      "  - c200_ttl\n",
      "  - c200_ctgl_299\n",
      "  - c200_ctgl_200\n",
      "  - c200_essay\n",
      "  - c200_test_us\n",
      "  - c200_test_ims\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: C300_compiled_dataframe.csv\n",
      "Number of rows: 1062\n",
      "Number of columns: 16\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - c300_wt_ttl\n",
      "  - c300_ttl\n",
      "  - c300_ctgl\n",
      "  - c300_test_us\n",
      "  - c300_test_ims\n",
      "  - c300_test2\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: C400_compiled_dataframe.csv\n",
      "Number of rows: 1063\n",
      "Number of columns: 31\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_acces\n",
      "  - availibilty\n",
      "  - c400_wt_ttl\n",
      "  - c400_ttl\n",
      "  - c400_quiz\n",
      "  - c400_ctgl\n",
      "  - c400_test_us\n",
      "  - c400_test_ims\n",
      "  - c400_remedial_exam_[total_pts:_0_score]_\n",
      "  - c400_quiz_us_1\n",
      "  - c400_quiz_ims_1\n",
      "  - c400_quiz_us_2\n",
      "  - c402b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - c403b_quiz_(us)_[total_pts:_100_score]_\n",
      "  - c403b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - c404b_quiz_(us)_[total_pts:_100_score]_\n",
      "  - c404b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - c405b_quiz_(us)_[total_pts:_100_score]_\n",
      "  - c405b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - c406b_quiz_(us)_[total_pts:_100_score]_\n",
      "  - c406b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - c407b_quiz_(us)_[total_pts:_100_score]_\n",
      "  - c407b_quiz_(ims)_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: C500_compiled_dataframe.csv\n",
      "Number of rows: 1061\n",
      "Number of columns: 17\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - c500_wt_ttl\n",
      "  - c500_ttl\n",
      "  - c500_exam_ims\n",
      "  - c500_exam_us\n",
      "  - c500_cgtl\n",
      "  - c500_essay\n",
      "  - c500_practicum_ctgl\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: F100_compiled_dataframe.csv\n",
      "Number of rows: 1062\n",
      "Number of columns: 18\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availiability\n",
      "  - f100_wt_ttl\n",
      "  - f100_ttl\n",
      "  - f100_change_proposal\n",
      "  - f100_exam_ims\n",
      "  - f100_exam_us\n",
      "  - f100_azck1\n",
      "  - f100_azck2\n",
      "  - f100_presentation\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: H100_compiled_dataframe.csv\n",
      "Number of rows: 1060\n",
      "Number of columns: 15\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - h100_wt_ttl\n",
      "  - h100_ttl\n",
      "  - h100_ctgl\n",
      "  - h100_outline\n",
      "  - h100_essay\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: H400_compiled_dataframe.csv\n",
      "Number of rows: 1038\n",
      "Number of columns: 15\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - h400_wt_ttl\n",
      "  - h400_ttl\n",
      "  - h400_outline\n",
      "  - h400_esay\n",
      "  - h400_ctgl\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: L100_compiled_dataframe.csv\n",
      "Number of rows: 1063\n",
      "Number of columns: 17\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - total_[total_pts:_up_to_400_score]_\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - mid-point_ctgl_(0%)_[total_pts:_100_pass/fail]_\n",
      "  - l100a1_take_home_essay_exam_(60%)_[total_pts:_100_score]_\n",
      "  - l100a2_ctgl_(30%)_[total_pts:_100_score]_\n",
      "  - l100a3_critical_leadership_problem_identification_(10%)_[total_pts:_100_score]_\n",
      "  - ay24_ctgl_self-assessment_(required)_[total_pts:_0_complete/incomplete]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: L400_compiled_dataframe.csv\n",
      "Number of rows: 1037\n",
      "Number of columns: 17\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_400_score]_\n",
      "  - mid-point_individual_contribution_to_group_learning_(ctgl)_(0%)_[total_pts:_100_score]_\n",
      "  - l400a1_art_of_command_essay_exam_(base)_[total_pts:_100_score]_\n",
      "  - l400a1_art_of_command_essay_exam_(non-mos_option)_[total_pts:_100_score]_\n",
      "  - l400p_contribution_to_group_learning_[total_pts:_100_score]_\n",
      "  - ay24_ctgl_self-assessment_(required)_[total_pts:_0_complete/incomplete]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: M000_compiled_dataframe.csv\n",
      "Number of rows: 979\n",
      "Number of columns: 15\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - learner_id\n",
      "  - username\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_letter]_\n",
      "  - total_[total_pts:_up_to_300_score]_\n",
      "  - m000a1_individual_staff_product_running_estimate_[total_pts:_100_score]_\n",
      "  - m000a2_field_grade_officer_argumentative_essay_[total_pts:_100_score]_\n",
      "  - m000p_ctgl_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: M100_compiled_dataframe.csv\n",
      "Number of rows: 1039\n",
      "Number of columns: 16\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_400_score]_\n",
      "  - m100a1_division_deployment_coa_brief_[total_pts:_100_score]_\n",
      "  - m100b1_-_mod_1:_training_and_deployment_operations_(us_only)_[total_pts:_100_score]_\n",
      "  - m100p1_ctgl_[total_pts:_100_score]_\n",
      "  - m100b1_-_mod_1:_training_and_deployment_operations_(ims_only)_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: M200_compiled_dataframe.csv\n",
      "Number of rows: 1041\n",
      "Number of columns: 16\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_400_score]_\n",
      "  - m200p1_module_contribution_to_group_learning_-_individual_(30%)_[total_pts:_100_score]_\n",
      "  - m299a1_-__division_movement_plan_-_individual_(30%)_[total_pts:_100_score]_\n",
      "  - m200b1_u.s._officers_[total_pts:_100_score]_\n",
      "  - m200b1_ims_officers_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: M300_compiled_dataframe.csv\n",
      "Number of rows: 1040\n",
      "Number of columns: 16\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_400_score]_\n",
      "  - m300p_contribution_to_group_learning_(ctgl)_(20%)_[total_pts:_100_score]_\n",
      "  - m300a_individual_commander's_intent_and_planning_guidance_(40%)_[total_pts:_100_score]_\n",
      "  - m300b_module_iii_foundations_exam_-_ims_(40%)_[total_pts:_100_score]_\n",
      "  - m300b_module_iii_foundations_exam_-_us_(40%)_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: M400_compiled_dataframe.csv\n",
      "Number of rows: 1058\n",
      "Number of columns: 15\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_300_score]_\n",
      "  - m400a1_individual_running_estimate_(40_percent)_[total_pts:_100_score]_\n",
      "  - m400a2_individual_warfighting_function_point_paper_(40_percent)_[total_pts:_100_score]_\n",
      "  - m400p_individual_contribution_to_group_learning_(20_percent)_[total_pts:_100_score]_\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: S100_compiled_dataframe.csv\n",
      "Number of rows: 1061\n",
      "Number of columns: 25\n",
      "Columns:\n",
      "  - unique_id\n",
      "  - last_name\n",
      "  - first_name\n",
      "  - username\n",
      "  - learner_id\n",
      "  - last_access\n",
      "  - availability\n",
      "  - weighted_total_[total_pts:_up_to_100_percentage]_\n",
      "  - total_[total_pts:_up_to_1,050_score]_\n",
      "  - joint_log_planning_worksheet_[total_pts:_100_score]_\n",
      "  - s400_practical_exercise_[total_pts:_100_score]_\n",
      "  - s100b1_exam_number_1_(us_students)_[total_pts:_104_score]_\n",
      "  - s100b1_exam_number_1_(us_students)_[total_pts:_104_score]_.1\n",
      "  - s100b2_exam_number_2_(international_students)_[total_pts:_110_score]_\n",
      "  - s100a1_principles_of_sustainment_info_paper_[total_pts:_100_score]_\n",
      "  - s100b1_exam_#1_(us)_[total_pts:_100_score]_\n",
      "  - s100b1_exam_#1_(ims)_[total_pts:_100_score]_\n",
      "  - s100b2_exam_#2_(us)_[total_pts:_100_score]_\n",
      "  - s100b2_exam_#2_(ims)_[total_pts:_100_score]_\n",
      "  - ocs_check_on_learning_[total_pts:_32_score]_\n",
      "  - s100b1_exam_number_1_(us_students)_[total_pts:_104_score]_.2\n",
      "  - s100b1_exam_number_1_(us_students)_[total_pts:_104_score]_.3\n",
      "  - team\n",
      "  - section\n",
      "  - base_id\n",
      "\n",
      "File: test_output.csv\n",
      "Number of rows: 3\n",
      "Number of columns: 1\n",
      "Columns:\n",
      "  - Test\n",
      "\n",
      "End of report\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nReport on files in the cleaned_data folder:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"\\nFile: {file}\")\n",
    "            print(f\"Number of rows: {len(df)}\")\n",
    "            print(f\"Number of columns: {len(df.columns)}\")\n",
    "            print(\"Columns:\")\n",
    "            for col in df.columns:\n",
    "                print(f\"  - {col}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError reading file {file}:\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "print(\"\\nEnd of report\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
