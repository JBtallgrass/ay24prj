{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import janitor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Processing Function - run this once\n",
    "#### Cleaning the data from multiple csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file_paths, output_dir='cleaned_data'):\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    # Read the CSV files\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Remove columns with names starting with \"Unnamed\"\n",
    "            df = df.loc[:, ~df.columns.str.contains('^unnamed')]\n",
    "            dataframes.append((os.path.basename(file_path), df))\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Remove empty columns\n",
    "    dataframes = [(name, df.dropna(axis=1, how='all')) for name, df in dataframes]\n",
    "\n",
    "    # Correct data types\n",
    "    dataframes = [(name, df.convert_dtypes()) for name, df in dataframes]\n",
    "\n",
    "    # Replace blank cells with NaN\n",
    "    dataframes = [(name, df.replace(r'^\\s*$', np.nan, regex=True)) for name, df in dataframes]\n",
    "\n",
    "    # Rename columns to lowercase and replace spaces with underscores\n",
    "    for i, (name, df) in enumerate(dataframes):\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        dataframes[i] = (name, df)\n",
    "\n",
    "    # Split learner_id into team and section\n",
    "    for i, (name, df) in enumerate(dataframes):\n",
    "        if 'learner_id' in df.columns:\n",
    "            # Extract team and section using the correct pattern\n",
    "            extracted = df['learner_id'].str.extract(r'(\\d+)([A-Z])')\n",
    "            df.loc[:, 'team'] = extracted[0].astype(str).str.zfill(2)\n",
    "            df.loc[:, 'section'] = extracted[1]\n",
    "        dataframes[i] = (name, df)\n",
    "\n",
    "    # Remove the username column if it exists\n",
    "    for i, (name, df) in enumerate(dataframes):\n",
    "        if 'username' in df.columns:\n",
    "            df = df.drop(columns=['username'])\n",
    "        dataframes[i] = (name, df)\n",
    "\n",
    "    # Generate a unique identifier\n",
    "    for i, (name, df) in enumerate(dataframes):\n",
    "        if 'last_name' in df.columns and 'first_name' in df.columns and 'team' in df.columns and 'section' in df.columns:\n",
    "            # Fill missing section values with a placeholder\n",
    "            df['section'] = df['section'].fillna('0')\n",
    "            df['identifier'] = df['last_name'].str[0] + df['first_name'].str[0] + df['team'] + df['section']\n",
    "            \n",
    "            # Handle potential conflicts\n",
    "            counts = df['identifier'].value_counts()\n",
    "            conflicts = counts[counts > 1].index\n",
    "\n",
    "            for conflict in conflicts:\n",
    "                conflict_indices = df[df['identifier'] == conflict].index\n",
    "                for j, index in enumerate(conflict_indices):\n",
    "                    df.loc[index, 'identifier'] = f\"{conflict}{j+1}\"\n",
    "\n",
    "            # Move the identifier, team, and section to the leftmost columns\n",
    "            cols = df.columns.tolist()\n",
    "            new_order = ['identifier', 'team', 'section'] + [col for col in cols if col not in ['identifier', 'team', 'section']]\n",
    "            df = df[new_order]\n",
    "\n",
    "        dataframes[i] = (name, df)\n",
    "\n",
    "    # Save the cleaned dataframes to the output directory\n",
    "    for name, df in dataframes:\n",
    "        output_path = os.path.join(output_dir, name)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Define the Descriptive Analytics and Visualization Function (Run this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_analytics_and_visualization(dataframes, columns_dict, output_dir='images'):\n",
    "    for name, df in dataframes:\n",
    "        if name in columns_dict:\n",
    "            columns = columns_dict[name]\n",
    "            print(f\"Descriptive Analytics for {name}:\\n\")\n",
    "            print(df[columns].describe(include='all'))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Create the output directory if it does not exist\n",
    "            image_dir = os.path.join(output_dir, name.split('.')[0])\n",
    "            os.makedirs(image_dir, exist_ok=True)\n",
    "            \n",
    "            # Visualizations\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Distribution of Total Scores\n",
    "            if 'total' in columns:\n",
    "                plt.subplot(2, 2, 1)\n",
    "                sns.histplot(df['total'], kde=True)\n",
    "                plt.title('Distribution of Total Scores')\n",
    "                plt.xlabel('Total Scores')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.savefig(os.path.join(image_dir, 'distribution_of_total_scores.png'))\n",
    "                plt.clf()\n",
    "            \n",
    "            # Final Grade Distribution\n",
    "            if 'c100f_-_final_grade_(pass/fail)' in columns:\n",
    "                plt.subplot(2, 2, 2)\n",
    "                sns.countplot(x='c100f_-_final_grade_(pass/fail)', data=df)\n",
    "                plt.title('Final Grade Distribution (Pass/Fail)')\n",
    "                plt.xlabel('Final Grade (Pass/Fail)')\n",
    "                plt.ylabel('Count')\n",
    "                plt.savefig(os.path.join(image_dir, 'final_grade_distribution.png'))\n",
    "                plt.clf()\n",
    "            \n",
    "            # Argumentative Essay Scores Distribution\n",
    "            if 'c171a1_argumentative_essay' in columns:\n",
    "                plt.subplot(2, 2, 3)\n",
    "                sns.histplot(df['c171a1_argumentative_essay'], kde=True)\n",
    "                plt.title('Distribution of Argumentative Essay Scores')\n",
    "                plt.xlabel('Argumentative Essay Scores')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.savefig(os.path.join(image_dir, 'argumentative_essay_scores_distribution.png'))\n",
    "                plt.clf()\n",
    "            \n",
    "            # Info Brief Scores Distribution\n",
    "            if 'c172a1_info_brief_' in columns:\n",
    "                plt.subplot(2, 2, 4)\n",
    "                sns.histplot(df['c172a1_info_brief_'], kde=True)\n",
    "                plt.title('Distribution of Info Brief Scores')\n",
    "                plt.xlabel('Info Brief Scores')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.savefig(os.path.join(image_dir, 'info_brief_scores_distribution.png'))\n",
    "                plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: Process and Analyze Each File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['cleaned_data/C100.csv']\n",
    "processed_dataframes = process_files(file_paths)\n",
    "\n",
    "columns_dict = {\n",
    "    'C100.csv': ['total', 'c100f_-_final_grade_(pass/fail)', 'c100a1_idp', 'c171a1_argumentative_essay', 'c172a1_info_brief_', 'c400b1_diagnostic_exam_', 'f100b1_pretest_(u.s.)_', 'f100b1_pretest_(ims)', 's100b1_pretest_']\n",
    "}\n",
    "\n",
    "descriptive_analytics_and_visualization(processed_dataframes, columns_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['cleaned_data/C200.csv']\n",
    "processed_dataframes = process_files(file_paths)\n",
    "\n",
    "columns_dict = {\n",
    "    'C200.csv': ['total', 'c100f_-_final_grade_(pass/fail)', 'c100a1_idp', 'c171a1_argumentative_essay', 'c172a1_info_brief_', 'c400b1_diagnostic_exam_', 'f100b1_pretest_(u.s.)_', 'f100b1_pretest_(ims)', 's100b1_pretest_']\n",
    "}\n",
    "\n",
    "descriptive_analytics_and_visualization(processed_dataframes, columns_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
