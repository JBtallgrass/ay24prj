{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mulitple csv files\n",
    "csv_files = ['data/c200_SEC01.csv',\n",
    "             'data/c200_SEC02.csv',\n",
    "             'data/c200_SEC04.csv',\n",
    "             'data/c200_SEC05.csv',\n",
    "             'data/c200_SEC06.csv',\n",
    "             'data/c200_SEC07.csv',\n",
    "             'data/c200_SEC08.csv',\n",
    "             'data/c200_SEC09.csv',\n",
    "             'data/c200_SEC10.csv',\n",
    "             'data/c200_SEC11.csv', \n",
    "             'data/c200_SEC12.csv', \n",
    "             'data/c200_SEC13.csv', \n",
    "             'data/c200_SEC14.csv', \n",
    "             'data/c200_SEC15.csv',\n",
    "             'data/c200_SEC16.csv',\n",
    "             'data/c200_SEC17.csv',\n",
    "             'data/c200_SEC18.csv',\n",
    "             'data/c200_SEC19.csv'\n",
    "            ]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read the first CSV file to get the column headers\n",
    "initial_df = pd.read_csv(csv_files[0])\n",
    "initial_columns = initial_df.columns\n",
    "\n",
    "# Loop through the list of files\n",
    "for file in csv_files:\n",
    "    # Read the current CSV file into a DataFrame, ensuring it matches the initial columns\n",
    "    df = pd.read_csv(file, usecols=lambda column: column in initial_columns).reindex(columns=initial_columns)\n",
    "       \n",
    "    # Drop rows where all cells are blank\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "c200_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Optionally, handle blanks in the compiled DataFrame as well\n",
    "\n",
    "# Save the compiled DataFrame\n",
    "c200_df.to_csv('cleaned_data/c200_compiled_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
